{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['bert-base-uncased', 'distilbert-base-uncased', 'roberta-base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(map(lambda x:x.split(\"-\")[0]+\"_prob\", models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_prob', 'distilbert_prob', 'roberta_prob']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/macab/research/robust-representation-learning/concept-explanation/outputs/imdb_sst2_sa/sst2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>distilbert_pred</th>\n",
       "      <th>distilbert_prob</th>\n",
       "      <th>roberta_pred</th>\n",
       "      <th>roberta_prob</th>\n",
       "      <th>bert_pred</th>\n",
       "      <th>bert_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it's a charming and often affecting journey.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998655</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unflinchingly bleak and desperate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.935675</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allows us to hope that nolan is poised to emba...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995805</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975733</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the acting, costumes, music, cinematography an...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960720</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988386</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's slow - - very, very slow.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947970</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993910</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ground_truth  \\\n",
       "0       it's a charming and often affecting journey.             1   \n",
       "1                  unflinchingly bleak and desperate             0   \n",
       "2  allows us to hope that nolan is poised to emba...             1   \n",
       "3  the acting, costumes, music, cinematography an...             1   \n",
       "4                     it's slow - - very, very slow.             0   \n",
       "\n",
       "   distilbert_pred  distilbert_prob  roberta_pred  roberta_prob  bert_pred  \\\n",
       "0                1         0.998421             1      0.998655          1   \n",
       "1                0         0.935675             0      0.987056          0   \n",
       "2                1         0.995805             1      0.975733          1   \n",
       "3                1         0.960720             1      0.988386          0   \n",
       "4                0         0.947970             0      0.993910          0   \n",
       "\n",
       "   bert_prob  \n",
       "0   0.997684  \n",
       "1   0.684826  \n",
       "2   0.995648  \n",
       "3   0.181109  \n",
       "4   0.970273  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean_prob'] = df[models].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>distilbert_pred</th>\n",
       "      <th>distilbert_prob</th>\n",
       "      <th>roberta_pred</th>\n",
       "      <th>roberta_prob</th>\n",
       "      <th>bert_pred</th>\n",
       "      <th>bert_prob</th>\n",
       "      <th>mean_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it's a charming and often affecting journey.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998655</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997684</td>\n",
       "      <td>0.998253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unflinchingly bleak and desperate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.935675</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684826</td>\n",
       "      <td>0.869185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allows us to hope that nolan is poised to emba...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995805</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975733</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>0.989062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the acting, costumes, music, cinematography an...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960720</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988386</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181109</td>\n",
       "      <td>0.710072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's slow - - very, very slow.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947970</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993910</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970273</td>\n",
       "      <td>0.970718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ground_truth  \\\n",
       "0       it's a charming and often affecting journey.             1   \n",
       "1                  unflinchingly bleak and desperate             0   \n",
       "2  allows us to hope that nolan is poised to emba...             1   \n",
       "3  the acting, costumes, music, cinematography an...             1   \n",
       "4                     it's slow - - very, very slow.             0   \n",
       "\n",
       "   distilbert_pred  distilbert_prob  roberta_pred  roberta_prob  bert_pred  \\\n",
       "0                1         0.998421             1      0.998655          1   \n",
       "1                0         0.935675             0      0.987056          0   \n",
       "2                1         0.995805             1      0.975733          1   \n",
       "3                1         0.960720             1      0.988386          0   \n",
       "4                0         0.947970             0      0.993910          0   \n",
       "\n",
       "   bert_prob  mean_prob  \n",
       "0   0.997684   0.998253  \n",
       "1   0.684826   0.869185  \n",
       "2   0.995648   0.989062  \n",
       "3   0.181109   0.710072  \n",
       "4   0.970273   0.970718  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>distilbert_pred</th>\n",
       "      <th>distilbert_prob</th>\n",
       "      <th>roberta_pred</th>\n",
       "      <th>roberta_prob</th>\n",
       "      <th>bert_pred</th>\n",
       "      <th>bert_prob</th>\n",
       "      <th>mean_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>in this respect, bringing steve jobs back to s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.616070</td>\n",
       "      <td>0</td>\n",
       "      <td>0.960283</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817080</td>\n",
       "      <td>0.797811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>jon's defense began to weaken and slow. jon fe...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.769695</td>\n",
       "      <td>2</td>\n",
       "      <td>0.973326</td>\n",
       "      <td>2</td>\n",
       "      <td>0.858740</td>\n",
       "      <td>0.867254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>a little past the small theater built for loca...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.979074</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987399</td>\n",
       "      <td>2</td>\n",
       "      <td>0.979261</td>\n",
       "      <td>0.981911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8818</th>\n",
       "      <td>it is at the moment of maximum audience suscep...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607033</td>\n",
       "      <td>2</td>\n",
       "      <td>0.233893</td>\n",
       "      <td>2</td>\n",
       "      <td>0.353130</td>\n",
       "      <td>0.398019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6147</th>\n",
       "      <td>south carolina has no referendum right, so the...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.240270</td>\n",
       "      <td>2</td>\n",
       "      <td>0.823089</td>\n",
       "      <td>0</td>\n",
       "      <td>0.158566</td>\n",
       "      <td>0.407308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  ground_truth  \\\n",
       "7031  in this respect, bringing steve jobs back to s...             0   \n",
       "2672  jon's defense began to weaken and slow. jon fe...             2   \n",
       "1846  a little past the small theater built for loca...             2   \n",
       "8818  it is at the moment of maximum audience suscep...             0   \n",
       "6147  south carolina has no referendum right, so the...             2   \n",
       "\n",
       "      distilbert_pred  distilbert_prob  roberta_pred  roberta_prob  bert_pred  \\\n",
       "7031                0         0.616070             0      0.960283          0   \n",
       "2672                2         0.769695             2      0.973326          2   \n",
       "1846                2         0.979074             2      0.987399          2   \n",
       "8818                0         0.607033             2      0.233893          2   \n",
       "6147                1         0.240270             2      0.823089          0   \n",
       "\n",
       "      bert_prob  mean_prob  \n",
       "7031   0.817080   0.797811  \n",
       "2672   0.858740   0.867254  \n",
       "1846   0.979261   0.981911  \n",
       "8818   0.353130   0.398019  \n",
       "6147   0.158566   0.407308  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = df['mean_prob'].quantile(q=0.90)\n",
    "bottom_5 = df['mean_prob'].quantile(q=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_5 = df[df['mean_prob'] >= top_5]\n",
    "df_bottom_5 = df[df['mean_prob'] <= bottom_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(982, 9) (982, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df_top_5.shape, df_bottom_5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>mean_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1846</th>\n",
       "      <td>a little past the small theater built for loca...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.981911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>agency officials stated that copies of both th...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.958203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9545</th>\n",
       "      <td>there were beads of perspiration on his brow. ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.978763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>all these sites will automatically lead into g...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.975238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>they post loads of newspaper articles - - yaho...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.990727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>i have kept you and clothed you and fed you! i...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.990570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>madrid is the perfect base for explorations in...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.983962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>she graduated in 1995 owing $ 58, 000 in loans...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.985352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>the road along the coastline to the south trav...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.984317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>there are also ferries to discovery bay. there...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.990402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  ground_truth  \\\n",
       "1846  a little past the small theater built for loca...             2   \n",
       "1220  agency officials stated that copies of both th...             2   \n",
       "9545  there were beads of perspiration on his brow. ...             2   \n",
       "9118  all these sites will automatically lead into g...             2   \n",
       "3036  they post loads of newspaper articles - - yaho...             2   \n",
       "3791  i have kept you and clothed you and fed you! i...             2   \n",
       "7040  madrid is the perfect base for explorations in...             2   \n",
       "1133  she graduated in 1995 owing $ 58, 000 in loans...             2   \n",
       "4743  the road along the coastline to the south trav...             2   \n",
       "8803  there are also ferries to discovery bay. there...             2   \n",
       "\n",
       "      mean_prob  \n",
       "1846   0.981911  \n",
       "1220   0.958203  \n",
       "9545   0.978763  \n",
       "9118   0.975238  \n",
       "3036   0.990727  \n",
       "3791   0.990570  \n",
       "7040   0.983962  \n",
       "1133   0.985352  \n",
       "4743   0.984317  \n",
       "8803   0.990402  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_5[['text', 'ground_truth', 'mean_prob']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>mean_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>for big raj - buffs, the supreme example of in...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.168860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>in the 19th century, when kashmir was the most...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.186806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6956</th>\n",
       "      <td>anwar el - sadat succeeded nasser in 1970. nas...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.117802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>do you trust me, uncle? gauve hesitated. gauve...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.212983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>and it needs work too, you know, in case i hav...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.213960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>sun ra's spaceships did not come, as it were, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.189352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>the ams system also allows users to search the...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.081396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5987</th>\n",
       "      <td>this formal review process guarantees represen...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.211944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>he jumped up, planting one hand on the chargin...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.148834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>the spear missed vrenna by only a hand - span....</td>\n",
       "      <td>2</td>\n",
       "      <td>0.141670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  ground_truth  \\\n",
       "160   for big raj - buffs, the supreme example of in...             2   \n",
       "8314  in the 19th century, when kashmir was the most...             2   \n",
       "6956  anwar el - sadat succeeded nasser in 1970. nas...             2   \n",
       "2844  do you trust me, uncle? gauve hesitated. gauve...             1   \n",
       "3259  and it needs work too, you know, in case i hav...             2   \n",
       "9062  sun ra's spaceships did not come, as it were, ...             2   \n",
       "2338  the ams system also allows users to search the...             2   \n",
       "5987  this formal review process guarantees represen...             2   \n",
       "3550  he jumped up, planting one hand on the chargin...             2   \n",
       "6429  the spear missed vrenna by only a hand - span....             2   \n",
       "\n",
       "      mean_prob  \n",
       "160    0.168860  \n",
       "8314   0.186806  \n",
       "6956   0.117802  \n",
       "2844   0.212983  \n",
       "3259   0.213960  \n",
       "9062   0.189352  \n",
       "2338   0.081396  \n",
       "5987   0.211944  \n",
       "3550   0.148834  \n",
       "6429   0.141670  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bottom_5[['text', 'ground_truth', 'mean_prob']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_5[['text', 'ground_truth', 'mean_prob']].to_csv(\"top_5_sst2.csv\", index=False)\n",
    "df_bottom_5[['text', 'ground_truth', 'mean_prob']].to_csv(\"bottom_5_sst2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>mean_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>a poignant, artfully crafted meditation on mor...</td>\n",
       "      <td>0.999529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>just as moving, uplifting and funny as ever.</td>\n",
       "      <td>0.999555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>a gorgeous, witty, seductive movie.</td>\n",
       "      <td>0.999628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>a deep and meaningful film.</td>\n",
       "      <td>0.999635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>... a fun little timewaster, helped especially...</td>\n",
       "      <td>0.999458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>this is a good script, good dialogue, funny ev...</td>\n",
       "      <td>0.999479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>this is a story of two misfits who don't stand...</td>\n",
       "      <td>0.999492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>yakusho and shimizu... create engaging charact...</td>\n",
       "      <td>0.999635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>it's a charming and often affecting journey.</td>\n",
       "      <td>0.999638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>a delightful coming-of-age story.</td>\n",
       "      <td>0.999649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  mean_prob\n",
       "793  a poignant, artfully crafted meditation on mor...   0.999529\n",
       "837      just as moving, uplifting and funny as ever.    0.999555\n",
       "442               a gorgeous, witty, seductive movie.    0.999628\n",
       "597                       a deep and meaningful film.    0.999635\n",
       "811  ... a fun little timewaster, helped especially...   0.999458\n",
       "840  this is a good script, good dialogue, funny ev...   0.999479\n",
       "456  this is a story of two misfits who don't stand...   0.999492\n",
       "658  yakusho and shimizu... create engaging charact...   0.999635\n",
       "428      it's a charming and often affecting journey.    0.999638\n",
       "842                 a delightful coming-of-age story.    0.999649"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_5[['text', 'mean_prob']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9340    0.9252    0.9296       428\n",
      "           1     0.9259    0.9346    0.9302       428\n",
      "\n",
      "    accuracy                         0.9299       856\n",
      "   macro avg     0.9299    0.9299    0.9299       856\n",
      "weighted avg     0.9299    0.9299    0.9299       856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=df['ground_truth'], y_pred=df['roberta_pred'], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Pretrained Representations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from config import config\n",
    "from utils import seed, create_trainer, update_results\n",
    "import pytorch_lightning as pl\n",
    "from evaluation import evaluate\n",
    "from dataset.loader import create_loaders\n",
    "from dataset.dataset import create_datasets\n",
    "from transformers import AutoTokenizer\n",
    "from Trainer import LightningModel\n",
    "from models.model import Model\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/macab/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "datasets = create_datasets(task='imdb_sst2_sa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = config['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, usefast=True, use_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.69ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.81ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.83ba/s]\n"
     ]
    }
   ],
   "source": [
    "loaders = create_loaders(\n",
    "        dataset=datasets,\n",
    "        task='imdb_sst2_sa',\n",
    "        tokenizer=tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LightningModel(\n",
    "    model_name=model_name,\n",
    "    task=\"imdb_sst2_sa\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.load_state_dict(\n",
    "    torch.load(\"./outputs/imdb_sst2_sa/distilbert-base-uncased/epoch=2.ckpt\", map_location=torch.device('cpu'))['state_dict']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 55/55 [02:12<00:00,  2.07s/it]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': tensor(0.8886, dtype=torch.float64),\n",
      " 'test_f1': tensor(0.8799, dtype=torch.float64),\n",
      " 'test_loss': tensor(0.2832),\n",
      " 'test_precision': tensor(0.8859, dtype=torch.float64),\n",
      " 'test_recall': tensor(0.8863, dtype=torch.float64)}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 55/55 [02:12<00:00,  2.41s/it]\n",
      "/home/macab/miniconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: The testing_epoch_end should not return anything as of 9.1.to log, use self.log(...) or self.write(...) directly in the LightningModule\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.283192902803421,\n",
       "  'test_precision': 0.8859083593174502,\n",
       "  'test_recall': 0.8863001392546848,\n",
       "  'test_acc': 0.8886363636363637,\n",
       "  'test_f1': 0.879886611908088}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(\n",
    "    model=lm,\n",
    "    test_dataloaders=loaders['sst2']['test']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./outputs/imdb_sst2_sa/sst2.csv\")\n",
    "m = list(map(lambda x:x.split(\"-\")[0]+\"_prob\", models))\n",
    "df['mean_prob'] = df[m].mean(axis=1)\n",
    "df.to_csv(\"./outputs/imdb_sst2_sa/sst2_mean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>distilbert_pred</th>\n",
       "      <th>distilbert_prob</th>\n",
       "      <th>roberta_pred</th>\n",
       "      <th>roberta_prob</th>\n",
       "      <th>bert_pred</th>\n",
       "      <th>bert_prob</th>\n",
       "      <th>mean_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it's a charming and often affecting journey.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998655</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997684</td>\n",
       "      <td>0.998253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unflinchingly bleak and desperate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.935675</td>\n",
       "      <td>0</td>\n",
       "      <td>0.987056</td>\n",
       "      <td>0</td>\n",
       "      <td>0.684826</td>\n",
       "      <td>0.869185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allows us to hope that nolan is poised to emba...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995805</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975733</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995648</td>\n",
       "      <td>0.989062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the acting, costumes, music, cinematography an...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960720</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988386</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181109</td>\n",
       "      <td>0.710072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's slow - - very, very slow.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947970</td>\n",
       "      <td>0</td>\n",
       "      <td>0.993910</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970273</td>\n",
       "      <td>0.970718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  ground_truth  \\\n",
       "0       it's a charming and often affecting journey.             1   \n",
       "1                  unflinchingly bleak and desperate             0   \n",
       "2  allows us to hope that nolan is poised to emba...             1   \n",
       "3  the acting, costumes, music, cinematography an...             1   \n",
       "4                     it's slow - - very, very slow.             0   \n",
       "\n",
       "   distilbert_pred  distilbert_prob  roberta_pred  roberta_prob  bert_pred  \\\n",
       "0                1         0.998421             1      0.998655          1   \n",
       "1                0         0.935675             0      0.987056          0   \n",
       "2                1         0.995805             1      0.975733          1   \n",
       "3                1         0.960720             1      0.988386          0   \n",
       "4                0         0.947970             0      0.993910          0   \n",
       "\n",
       "   bert_prob  mean_prob  \n",
       "0   0.997684   0.998253  \n",
       "1   0.684826   0.869185  \n",
       "2   0.995648   0.989062  \n",
       "3   0.181109   0.710072  \n",
       "4   0.970273   0.970718  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-52f62406fba5688e\n",
      "                            Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/macab/.cache/huggingface/datasets/csv/default-52f62406fba5688e/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0...\n",
      "Dataset csv downloaded and prepared to /home/macab/.cache/huggingface/datasets/csv/default-52f62406fba5688e/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "predictions =  load_dataset('csv', data_files='./outputs/imdb_sst2_sa/sst2_mean.csv')['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'ground_truth', 'distilbert_pred', 'distilbert_prob', 'roberta_pred', 'roberta_prob', 'bert_pred', 'bert_prob', 'mean_prob'],\n",
       "    num_rows: 872\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 38.08ba/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = predictions.filter(lambda example : example['mean_prob'] < 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'ground_truth', 'distilbert_pred', 'distilbert_prob', 'roberta_pred', 'roberta_prob', 'bert_pred', 'bert_prob', 'mean_prob'],\n",
       "    num_rows: 171\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.71ba/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized = predictions.map(lambda x: tokenizer(x['text'], padding='max_length', truncation=True, max_length=config['tasks']['mnli']['max_seq_length']), batched=True)\n",
    "\n",
    "tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in lm.model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 171/171 [00:10<00:00, 16.43it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = torch.empty((0, 768))\n",
    "for each in tqdm(tokenized):\n",
    "\n",
    "    _, out = lm(\n",
    "        input_ids=each['input_ids'].unsqueeze(0), \n",
    "        attention_mask=each['attention_mask'].unsqueeze(0),\n",
    "    )\n",
    "\n",
    "    outputs = torch.vstack((outputs, out))\n",
    "\n",
    "\n",
    "    # print(each['input_ids'].shape, each['attention_mask'].shape)\n",
    "\n",
    "    # print(outputs.shape)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([171, 768])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(outputs, \"./outputs/imdb_sst2_sa/sst2_finetuned.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.hstack?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HANS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset hans (/home/macab/.cache/huggingface/datasets/hans/plain_text/1.0.0/1bbcb735c482acd54f2e118074b59cfd2bf5f7a5a285d4d540d1e632216672ac)\n"
     ]
    }
   ],
   "source": [
    "hans = load_dataset(\"hans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'constituent', 'lexical_overlap', 'subsequence'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(hans['train']['heuristic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(hans['train']['template']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temp1',\n",
       " 'temp1',\n",
       " 'temp1',\n",
       " 'temp1',\n",
       " 'temp1',\n",
       " 'temp1',\n",
       " 'temp1',\n",
       " 'temp1',\n",
       " 'temp1',\n",
       " 'temp1']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hans['train']['template'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The doctors supported the scientist . The scientist supported the doctors .\n"
     ]
    }
   ],
   "source": [
    "print(hans['train']['premise'][0], hans['train']['hypothesis'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The secretaries introduced the judges . The judges introduced the secretaries .\n"
     ]
    }
   ],
   "source": [
    "print(hans['train']['premise'][2], hans['train']['hypothesis'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temp68',\n",
       " 'temp68',\n",
       " 'temp68',\n",
       " 'temp68',\n",
       " 'temp68',\n",
       " 'temp68',\n",
       " 'temp68',\n",
       " 'temp68',\n",
       " 'temp68',\n",
       " 'temp68']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hans['train']['template'][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_parse_hypothesis': '( ( The scientist ) ( ( supported ( the doctors ) ) . ) )',\n",
       " 'binary_parse_premise': '( ( The doctors ) ( ( supported ( the scientist ) ) . ) )',\n",
       " 'heuristic': 'lexical_overlap',\n",
       " 'hypothesis': 'The scientist supported the doctors .',\n",
       " 'label': 1,\n",
       " 'parse_hypothesis': '(ROOT (S (NP (DT The) (NN scientist)) (VP (VBD supported) (NP (DT the) (NNS doctors))) (. .)))',\n",
       " 'parse_premise': '(ROOT (S (NP (DT The) (NNS doctors)) (VP (VBD supported) (NP (DT the) (NN scientist))) (. .)))',\n",
       " 'premise': 'The doctors supported the scientist .',\n",
       " 'subcase': 'ln_subject/object_swap',\n",
       " 'template': 'temp1'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hans['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_parse_hypothesis': '( ( The tourist ) ( ( introduced ( the athletes ) ) . ) )',\n",
       " 'binary_parse_premise': '( ( The athletes ) ( ( introduced ( the tourist ) ) . ) )',\n",
       " 'heuristic': 'lexical_overlap',\n",
       " 'hypothesis': 'The tourist introduced the athletes .',\n",
       " 'label': 1,\n",
       " 'parse_hypothesis': '(ROOT (S (NP (DT The) (NN tourist)) (VP (VBD introduced) (NP (DT the) (NNS athletes))) (. .)))',\n",
       " 'parse_premise': '(ROOT (S (NP (DT The) (NNS athletes)) (VP (VBD introduced) (NP (DT the) (NN tourist))) (. .)))',\n",
       " 'premise': 'The athletes introduced the tourist .',\n",
       " 'subcase': 'ln_subject/object_swap',\n",
       " 'template': 'temp1'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hans['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'binary_parse_hypothesis': '( ( The managers ) ( ( stopped ( the scientist ) ) . ) )',\n",
       " 'binary_parse_premise': '( ( The tourist ) ( ( stopped ( ( the managers ) ( near ( the scientist ) ) ) ) . ) )',\n",
       " 'heuristic': 'lexical_overlap',\n",
       " 'hypothesis': 'The managers stopped the scientist .',\n",
       " 'label': 1,\n",
       " 'parse_hypothesis': '(ROOT (S (NP (DT The) (NNS managers)) (VP (VBD stopped) (NP (DT the) (NN scientist))) (. .)))',\n",
       " 'parse_premise': '(ROOT (S (NP (DT The) (NN tourist)) (VP (VBD stopped) (NP (NP (DT the) (NNS managers)) (PP (IN near) (NP (DT the) (NN scientist))))) (. .)))',\n",
       " 'premise': 'The tourist stopped the managers near the scientist .',\n",
       " 'subcase': 'ln_preposition',\n",
       " 'template': 'temp6'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hans['train'][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hans['train'][999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/macab/research/robust-representation-learning/concept-explanation/outputs/mnli/mnli_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['mean_prob'].quantile(q=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df[df['mean_prob']<0.20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the most important directions are simply up and up leads eventually to the cathedral and fortress commanding the hilltop, and down inevitably leads to one of three gates through the wall to the new town. go downwards to one of the gates, all of which will lead you into the cathedral.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['ground_truth'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1351020485162734"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['mean_prob'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8363298972447714"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mean_prob'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'constituent', 'lexical_overlap', 'subsequence'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(hans['train']['heuristic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HANS Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset hans (/home/macab/.cache/huggingface/datasets/hans/plain_text/1.0.0/1bbcb735c482acd54f2e118074b59cfd2bf5f7a5a285d4d540d1e632216672ac)\n"
     ]
    }
   ],
   "source": [
    "hans = load_dataset(\"hans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'parse_premise', 'parse_hypothesis', 'binary_parse_premise', 'binary_parse_hypothesis', 'heuristic', 'subcase', 'template'],\n",
       "        num_rows: 30000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/macab/research/robust-representation-learning/concept-explanation/outputs/hans/hans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>distilbert_pred</th>\n",
       "      <th>distilbert_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the president advised the doctor. the doctor a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the student saw the managers. the managers saw...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the presidents encouraged the banker. the bank...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the senators supported the actor. the actor su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the actors avoided the bankers. the bankers av...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  ground_truth  \\\n",
       "0  the president advised the doctor. the doctor a...             1   \n",
       "1  the student saw the managers. the managers saw...             1   \n",
       "2  the presidents encouraged the banker. the bank...             1   \n",
       "3  the senators supported the actor. the actor su...             1   \n",
       "4  the actors avoided the bankers. the bankers av...             1   \n",
       "\n",
       "   distilbert_pred  distilbert_prob  \n",
       "0                1         0.999649  \n",
       "1                1         0.999785  \n",
       "2                1         0.999706  \n",
       "3                1         0.999721  \n",
       "4                1         0.999353  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hypothesis'] = hans['validation']['hypothesis']\n",
    "df['premise'] = hans['validation']['premise']\n",
    "df['template'] = hans['validation']['template']\n",
    "df['heuristic'] = hans['validation']['heuristic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>distilbert_pred</th>\n",
       "      <th>distilbert_prob</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>premise</th>\n",
       "      <th>template</th>\n",
       "      <th>heuristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the president advised the doctor. the doctor a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999649</td>\n",
       "      <td>The doctor advised the president .</td>\n",
       "      <td>The president advised the doctor .</td>\n",
       "      <td>temp1</td>\n",
       "      <td>lexical_overlap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the student saw the managers. the managers saw...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>The managers saw the student .</td>\n",
       "      <td>The student saw the managers .</td>\n",
       "      <td>temp1</td>\n",
       "      <td>lexical_overlap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the presidents encouraged the banker. the bank...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999706</td>\n",
       "      <td>The banker encouraged the presidents .</td>\n",
       "      <td>The presidents encouraged the banker .</td>\n",
       "      <td>temp1</td>\n",
       "      <td>lexical_overlap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the senators supported the actor. the actor su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999721</td>\n",
       "      <td>The actor supported the senators .</td>\n",
       "      <td>The senators supported the actor .</td>\n",
       "      <td>temp1</td>\n",
       "      <td>lexical_overlap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the actors avoided the bankers. the bankers av...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999353</td>\n",
       "      <td>The bankers avoided the actors .</td>\n",
       "      <td>The actors avoided the bankers .</td>\n",
       "      <td>temp1</td>\n",
       "      <td>lexical_overlap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  ground_truth  \\\n",
       "0  the president advised the doctor. the doctor a...             1   \n",
       "1  the student saw the managers. the managers saw...             1   \n",
       "2  the presidents encouraged the banker. the bank...             1   \n",
       "3  the senators supported the actor. the actor su...             1   \n",
       "4  the actors avoided the bankers. the bankers av...             1   \n",
       "\n",
       "   distilbert_pred  distilbert_prob                              hypothesis  \\\n",
       "0                1         0.999649      The doctor advised the president .   \n",
       "1                1         0.999785          The managers saw the student .   \n",
       "2                1         0.999706  The banker encouraged the presidents .   \n",
       "3                1         0.999721      The actor supported the senators .   \n",
       "4                1         0.999353        The bankers avoided the actors .   \n",
       "\n",
       "                                  premise template        heuristic  \n",
       "0      The president advised the doctor .    temp1  lexical_overlap  \n",
       "1          The student saw the managers .    temp1  lexical_overlap  \n",
       "2  The presidents encouraged the banker .    temp1  lexical_overlap  \n",
       "3      The senators supported the actor .    temp1  lexical_overlap  \n",
       "4        The actors avoided the bankers .    temp1  lexical_overlap  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df[df['distilbert_prob']<0.20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>distilbert_pred</th>\n",
       "      <th>distilbert_prob</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>premise</th>\n",
       "      <th>template</th>\n",
       "      <th>heuristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>the authors by the senators advised the presid...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068715</td>\n",
       "      <td>The presidents advised the authors .</td>\n",
       "      <td>The authors by the senators advised the presid...</td>\n",
       "      <td>temp3</td>\n",
       "      <td>lexical_overlap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>the bankers by the scientists encouraged the m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167058</td>\n",
       "      <td>The managers encouraged the bankers .</td>\n",
       "      <td>The bankers by the scientists encouraged the m...</td>\n",
       "      <td>temp3</td>\n",
       "      <td>lexical_overlap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>the author by the bankers saw the doctor. the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086606</td>\n",
       "      <td>The doctor saw the author .</td>\n",
       "      <td>The author by the bankers saw the doctor .</td>\n",
       "      <td>temp3</td>\n",
       "      <td>lexical_overlap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>the secretary by the presidents advised the ju...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068734</td>\n",
       "      <td>The judge advised the secretary .</td>\n",
       "      <td>The secretary by the presidents advised the ju...</td>\n",
       "      <td>temp3</td>\n",
       "      <td>lexical_overlap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>the athlete by the authors believed the presid...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175073</td>\n",
       "      <td>The president believed the athlete .</td>\n",
       "      <td>The athlete by the authors believed the presid...</td>\n",
       "      <td>temp3</td>\n",
       "      <td>lexical_overlap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             input_text  ground_truth  \\\n",
       "1070  the authors by the senators advised the presid...             1   \n",
       "1460  the bankers by the scientists encouraged the m...             1   \n",
       "1489  the author by the bankers saw the doctor. the ...             1   \n",
       "1608  the secretary by the presidents advised the ju...             1   \n",
       "1673  the athlete by the authors believed the presid...             1   \n",
       "\n",
       "      distilbert_pred  distilbert_prob                             hypothesis  \\\n",
       "1070                0         0.068715   The presidents advised the authors .   \n",
       "1460                0         0.167058  The managers encouraged the bankers .   \n",
       "1489                0         0.086606            The doctor saw the author .   \n",
       "1608                0         0.068734      The judge advised the secretary .   \n",
       "1673                0         0.175073   The president believed the athlete .   \n",
       "\n",
       "                                                premise template  \\\n",
       "1070  The authors by the senators advised the presid...    temp3   \n",
       "1460  The bankers by the scientists encouraged the m...    temp3   \n",
       "1489         The author by the bankers saw the doctor .    temp3   \n",
       "1608  The secretary by the presidents advised the ju...    temp3   \n",
       "1673  The athlete by the authors believed the presid...    temp3   \n",
       "\n",
       "            heuristic  \n",
       "1070  lexical_overlap  \n",
       "1460  lexical_overlap  \n",
       "1489  lexical_overlap  \n",
       "1608  lexical_overlap  \n",
       "1673  lexical_overlap  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_csv(\"./outputs/hans/bottom_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df[df['distilbert_prob']>0.999942]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv(\"./outputs/hans/top_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df[df['distilbert_prob']<0.50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcf10e5a790>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_3['heuristic'].value_counts().plot(kind=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df[df['distilbert_prob']>0.50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcf10e43130>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_4['heuristic'].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b98eaffda2f8dccdd434b8a538c0dff68c3263c07983948f9c516c57469e3c42"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}